# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/utils.ipynb (unless otherwise specified).

__all__ = ['create_path', 'create_loader', 'check_exists', 'download_file_from_google_drive']

# Cell
import os
import torch
import requests

import snapworth.dataset.dataset as dataset
from pathlib import Path

# Cell
def create_path(path):
    if not os.path.exists(path):
        path.mkdir(parents=True, exist_ok=True)
    return path

# Cell
def create_loader(imgs, lbls, bs, resize=True, drop_last=False, shuffle=False):
    assert len(imgs) == len(lbls)
    image_ds = dataset.ImageDataset(imgs, lbls, resize=resize)
    image_dl = torch.utils.data.DataLoader(image_ds, batch_size=bs, drop_last=drop_last,
                                        num_workers=5, shuffle=shuffle)
    return image_dl

# Cell
def check_exists(path):
    if not isinstance(path, Path): path = Path(path)
    if path.exists():
        return
    else:
        os.makedirs(path)

# Cell
def download_file_from_google_drive(id, destination):
    def get_confirm_token(response):
        for key, value in response.cookies.items():
            if key.startswith('download_warning'):
                return value

        return None

    def save_response_content(response, destination):
        CHUNK_SIZE = 32768

        with open(destination, "wb") as f:
            for chunk in response.iter_content(CHUNK_SIZE):
                if chunk:  # filter out keep-alive new chunks
                    f.write(chunk)

    URL = "https://docs.google.com/uc?export=download"

    session = requests.Session()

    response = session.get(URL, params = { 'id' : id }, stream = True)
    token = get_confirm_token(response)

    if token:
        params = { 'id' : id, 'confirm' : token }
        response = session.get(URL, params = params, stream = True)

    save_response_content(response, destination)
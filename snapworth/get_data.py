# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/get_data.ipynb (unless otherwise specified).

__all__ = ['df', 'img_data_urls', 'unique_id', 'download', 'download_all']

# Cell
import os
import time
import shutil
import pandas as pd

from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
import snapworth.config as config
import snapworth.utils.utils as utils
from fastai.data.external import download_url

# Cell
df = pd.read_csv(config.DATA_PATH/'all_data.csv')

# Cell
img_data_urls = df.product_image_url.values
unique_id = df.index.values

# Cell
def download(img_data_urls, img_data_names, path):
    mb = tqdm(list(zip(img_data_urls, img_data_names)))

    for url, category in mb:
        dir_ = utils.create_path(path/f'images')
        img_path = dir_/f'{category}.jpg'
        if not os.path.exists(img_path):  #maybe try to open file with a try except
            if url.startswith('http'):
                url = url
            else:
                print(f'Check the urls for image {category}')
            download_url(url, img_path, show_progress=False)
        else:
            continue

def download_all(path, img_data_urls, img_data_names):
    with ThreadPoolExecutor(max_workers = 300) as executor:
        executor.submit(download, img_data_urls, unique_id, path)

# Cell
if __name__ == '__main__':
    download_all(config.DATA_PATH, img_data_urls, unique_id)